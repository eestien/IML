{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1584b-56b4-49c6-b1dd-f47a519963a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import gensim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "eeadc323-81d7-4721-b602-169e087f53c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\artem.kuzmin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) | set(stopwords.words('french')) | set(stopwords.words('italian'))\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e5c4a-ed31-42f1-9662-f13f263c4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    \"GoogleNews-vectors-negative300.bin.gz\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a714f00-eb51-4ca4-9e2b-4218a574fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('each_genre200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221bb15-32bb-42f8-92cf-9fda368d8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c648f8e-77ae-4953-93b1-ca7a8206ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_w2v_vectors(sentence):\n",
    "    avg_vector = np.zeros(300)\n",
    "    for word in sentence:\n",
    "        if (word in w2vec):\n",
    "            avg_vector += w2vec[word]\n",
    "    if (len(sentence)==0):\n",
    "        return avg_vector\n",
    "    return avg_vector/len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57d7f9-2a8a-4b0b-9adf-a9f66d3ae48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_XY(df):\n",
    "    X = df[['title','description']]\n",
    "    y = df['first_genre']\n",
    "    X['cleaned_titles'] = X['title'].apply(lambda x: clean_text(x))\n",
    "    X['cleaned_descriptions'] = X['description'].apply(lambda x: clean_text(x))\n",
    "    X['tokenized_titles'] = X['cleaned_titles'].apply(lambda x: x.split())\n",
    "    X['tokenized_descriptions'] = X['cleaned_descriptions'].apply(lambda x: x.split())\n",
    "    X['w2v_avg_titles'] = X['tokenized_titles'].apply(lambda line: create_avg_w2v_vectors(line))\n",
    "    X['w2v_avg_descriptions'] = X['tokenized_descriptions'].apply(lambda line: create_avg_w2v_vectors(line))\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    return X,y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "705a832b-38bf-4f7b-b21d-3a69253a0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train,y_train):\n",
    "    model = SVC(kernel='rbf',probability=True)\n",
    "    svc_params = {\"C\": list(np.arange(0.1,2.5,0.1))}\n",
    "\n",
    "    model_cv = GridSearchCV(model, svc_params, cv=3, n_jobs=-1,verbose=2).fit(X_train,y_train)\n",
    "    model = SVC(kernel='rbf',C=model_cv.best_params_['C'],probability=True).fit(X_train,y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def predict(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_probs = model.predict_proba(X_test)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    prec = precision_score(y_test,y_pred,average=\"weighted\")\n",
    "    f1 = f1_score(y_test,y_pred,average=\"weighted\")\n",
    "    print(f\"ROC_AUC:{roc_auc}\")\n",
    "    print(f\"Accuracy:{acc}\")\n",
    "    print(f\"Precision:{prec}\")\n",
    "    print(f\"F1-score:{f1}\")\n",
    "    \n",
    "    return y_pred,y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "492386af-6775-423b-a807-b86edfec42d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem.kuzmin\\AppData\\Local\\Temp\\ipykernel_28184\\3871449531.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['cleaned_titles'] = X['title'].apply(lambda x: clean_text(x))\n",
      "C:\\Users\\artem.kuzmin\\AppData\\Local\\Temp\\ipykernel_28184\\3871449531.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['cleaned_descriptions'] = X['description'].apply(lambda x: clean_text(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem.kuzmin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC:0.6894792203549827\n",
      "Accuracy:0.18203309692671396\n",
      "Precision:0.1811324192795199\n",
      "F1-score:0.16923150841832893\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "ROC_AUC:0.8583927840425705\n",
      "Accuracy:0.3416075650118203\n",
      "Precision:0.3207744821095317\n",
      "F1-score:0.32746349667036495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem.kuzmin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X,y = extract_XY(df)\n",
    "X_train_titles, X_test_titles, y_train_titles, y_test_titles = train_test_split(X[f'w2v_avg_titles'], y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_titles, X_test_titles = list(X_train_titles), list(X_test_titles)\n",
    "\n",
    "X_train_descriptions, X_test_descriptions, y_train_descriptions, y_test_descriptions = train_test_split(X[f'w2v_avg_descriptions'], y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train_descriptions, X_test_descriptions = list(X_train_descriptions), list(X_test_descriptions)\n",
    "\n",
    "model_titles = train_model(X_train_titles,y_train_titles)\n",
    "y_pred_titles,_ = predict(model_titles,X_test_titles,y_test_titles)\n",
    "\n",
    "model_descriptions = train_model(X_train_descriptions,y_train_descriptions)\n",
    "y_pred_descriptions,_ = predict(model_descriptions,X_test_descriptions,y_test_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2990adf-0096-4971-a4fa-1267db02c637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
